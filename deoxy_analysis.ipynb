{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8231534090909092\n",
      "RPC 0.7548115079365079\n",
      "IBM 0.6449032738095237\n",
      "IBPL 0.5928199404761905\n",
      "LRRF 0.6692708333333333\n",
      "LRT 0.7492559523809523\n",
      "rfr 0.7140562996031746\n",
      "\n",
      "baseline 0.3937225548404685\n",
      "RPC 0.5218501702536795\n",
      "IBM 0.2425911553633965\n",
      "IBPL 0.23998126943347037\n",
      "LRRF 0.2959613833167991\n",
      "LRT 0.3947883095628495\n",
      "rfr 0.41315789473684217\n",
      "11 32\n",
      "13 32\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_both_desc.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRT\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8231534090909092\n",
      "RPC 0.7563244047619048\n",
      "IBM 0.686061507936508\n",
      "IBPL 0.6825129731379731\n",
      "LRRF 0.6042906746031746\n",
      "LRT 0.7492559523809523\n",
      "rfr 0.6924355158730159\n",
      "\n",
      "baseline 0.3937225548404685\n",
      "RPC 0.46509794433443036\n",
      "IBM 0.3166668251662633\n",
      "IBPL 0.26817766975626933\n",
      "LRRF 0.30469479003088396\n",
      "LRT 0.3947883095628495\n",
      "rfr 0.37532894736842104\n",
      "10 32\n",
      "14 32\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_both_fp.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRT\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8231534090909092\n",
      "RPC 0.6861742424242424\n",
      "BoostRPC 0.1341661376817627\n",
      "IBM 0.5600818452380952\n",
      "IBPL 0.51796875\n",
      "LRRF 0.7010551948051948\n",
      "LRT 0.7492559523809523\n",
      "BoostLRT 0.11769549894549894\n",
      "rfr 0.7140562996031746\n",
      "\n",
      "baseline 0.3937225548404685\n",
      "RPC 0.3682708478957354\n",
      "BoostRPC -0.3742604355471656\n",
      "IBM 0.3044204799928655\n",
      "IBPL 0.23364141665263524\n",
      "LRRF 0.36511842763487357\n",
      "LRT 0.3947883095628495\n",
      "BoostLRT -0.4007598105362346\n",
      "rfr 0.41315789473684217\n",
      "11 32\n",
      "13 32\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_both_desc.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRT\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.8231534090909092\n",
      "RPC 0.6861742424242424\n",
      "IBM 0.6538070436507937\n",
      "IBPL 0.7205729166666667\n",
      "LRRF 0.7010551948051948\n",
      "LRT 0.7492559523809523\n",
      "rfr 0.6924355158730159\n",
      "\n",
      "baseline 0.3937225548404685\n",
      "RPC 0.36892874263257747\n",
      "IBM 0.30090563978414286\n",
      "IBPL 0.24895686724609356\n",
      "LRRF 0.36511842763487357\n",
      "LRT 0.3947883095628495\n",
      "rfr 0.37532894736842104\n",
      "23 32\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_both_fp.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRRF\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr >= rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_both_onehot.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRRF\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr >= rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.509375\n",
      "RPC 0.6067708333333333\n",
      "IBM 0.5015625\n",
      "IBPL 0.4463541666666667\n",
      "LRRF 0.7265625\n",
      "LRT 0.6557291666666666\n",
      "rfr 0.5807291666666666\n",
      "\n",
      "baseline 0.1305793193816164\n",
      "RPC 0.17148007132581644\n",
      "IBM 0.013138402495312654\n",
      "IBPL 0.024648552018617848\n",
      "LRRF 0.40885853031859287\n",
      "LRT 0.3196312574999723\n",
      "rfr 0.3964292135596641\n",
      "69 160\n",
      "56 160\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n",
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_base_desc.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRRF\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.509375\n",
      "RPC 0.6098958333333334\n",
      "IBM 0.5145833333333333\n",
      "IBPL 0.5\n",
      "LRRF 0.6192708333333333\n",
      "LRT 0.7260416666666666\n",
      "rfr 0.6333333333333333\n",
      "\n",
      "baseline 0.1305793193816164\n",
      "RPC 0.2027670152246771\n",
      "IBM -0.0010279692298041352\n",
      "IBPL -0.01104196643661246\n",
      "LRRF 0.20691938974298557\n",
      "LRT 0.3593208341015309\n",
      "rfr 0.35471823016070114\n",
      "63 160\n",
      "52 160\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(ncols=2, figsize=(12,6))\n",
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_base_fp.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRT\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.705078125\n",
      "RPC 0.694921875\n",
      "IBM 0.705078125\n",
      "IBPL 0.705078125\n",
      "LRRF 0.7\n",
      "LRT 0.6618489583333333\n",
      "rfr 0.6682291666666667\n",
      "\n",
      "baseline 0.47375168898584674\n",
      "RPC 0.5133727925319449\n",
      "IBM -0.024151755758702424\n",
      "IBPL 0.5118102925319449\n",
      "LRRF 0.5149352925319448\n",
      "LRT 0.41013448189365065\n",
      "rfr 0.3906199349152649\n",
      "\n",
      "29 128\n",
      "82 128\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_sulfonyl_fluoride_desc.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "print()\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"LRRF\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 0.705078125\n",
      "RPC 0.762890625\n",
      "IBM 0.6334635416666667\n",
      "IBPL 0.6334635416666667\n",
      "LRRF 0.705078125\n",
      "LRT 0.7424479166666667\n",
      "rfr 0.7127604166666667\n",
      "\n",
      "baseline 0.47375168898584674\n",
      "RPC 0.5383727925319448\n",
      "IBM 0.2356415995816768\n",
      "IBPL 0.2525755407376637\n",
      "LRRF 0.5071227925319448\n",
      "LRT 0.47578827291727377\n",
      "rfr 0.4298326497565047\n",
      "\n",
      "20 128\n",
      "98 128\n"
     ]
    }
   ],
   "source": [
    "perf = joblib.load(\"performance_excels/deoxy_performance_dict_sulfonyl_fluoride_fp.joblib\")\n",
    "perf_df = pd.DataFrame(perf)\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"reciprocal_rank\"].mean())\n",
    "print()\n",
    "for model in perf_df[\"model\"].unique() :\n",
    "    print(model, perf_df[perf_df[\"model\"] == model][\"kendall_tau\"].mean())\n",
    "print()\n",
    "lrrf_rr = perf_df[perf_df[\"model\"] == \"RPC\"][\"reciprocal_rank\"].values\n",
    "rfr_rr = perf_df[perf_df[\"model\"] == \"rfr\"][\"reciprocal_rank\"].values\n",
    "print(sum(lrrf_rr > rfr_rr), len(lrrf_rr))\n",
    "print(sum(lrrf_rr == rfr_rr), len(lrrf_rr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to combine ranking base & ranking sulfonyl fluorides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 20) (128, 5) (160, 22) (160, 4) (32, 19) (32, 20)\n",
      "Test compound 0\n",
      "  Kendall Tau\n",
      "   Combined: 0.39999999999999997\n",
      "   At once: 0.7263157894736842\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 1\n",
      "  Kendall Tau\n",
      "   Combined: 0.1368421052631579\n",
      "   At once: 0.3157894736842105\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 0.25\n",
      "\n",
      "Test compound 2\n",
      "  Kendall Tau\n",
      "   Combined: 0.4421052631578947\n",
      "   At once: -0.031578947368421054\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 0.2\n",
      "\n",
      "Test compound 3\n",
      "  Kendall Tau\n",
      "   Combined: 0.30526315789473685\n",
      "   At once: 0.7473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.2\n",
      "   At once: 0.5\n",
      "\n",
      "Test compound 4\n",
      "  Kendall Tau\n",
      "   Combined: 0.031578947368421054\n",
      "   At once: 0.3473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.16666666666666666\n",
      "   At once: 0.25\n",
      "\n",
      "Test compound 5\n",
      "  Kendall Tau\n",
      "   Combined: 0.1473684210526316\n",
      "   At once: 0.17894736842105263\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 0.2\n",
      "\n",
      "Test compound 6\n",
      "  Kendall Tau\n",
      "   Combined: 0.23157894736842105\n",
      "   At once: 0.28421052631578947\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 0.3333333333333333\n",
      "\n",
      "Test compound 7\n",
      "  Kendall Tau\n",
      "   Combined: 0.2631578947368421\n",
      "   At once: 0.15789473684210525\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 0.2\n",
      "\n",
      "Test compound 8\n",
      "  Kendall Tau\n",
      "   Combined: 0.39999999999999997\n",
      "   At once: 0.6210526315789474\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 9\n",
      "  Kendall Tau\n",
      "   Combined: 0.5368421052631579\n",
      "   At once: 0.7263157894736842\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 10\n",
      "  Kendall Tau\n",
      "   Combined: 0.4631578947368421\n",
      "   At once: 0.5473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 11\n",
      "  Kendall Tau\n",
      "   Combined: 0.43157894736842106\n",
      "   At once: 0.43157894736842106\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 12\n",
      "  Kendall Tau\n",
      "   Combined: 0.631578947368421\n",
      "   At once: 0.6210526315789474\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 13\n",
      "  Kendall Tau\n",
      "   Combined: 0.5157894736842106\n",
      "   At once: 0.5473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 14\n",
      "  Kendall Tau\n",
      "   Combined: 0.042105263157894736\n",
      "   At once: 0.6736842105263158\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.14285714285714285\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 15\n",
      "  Kendall Tau\n",
      "   Combined: 0.021052631578947368\n",
      "   At once: 0.7368421052631579\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 16\n",
      "  Kendall Tau\n",
      "   Combined: 0.16842105263157894\n",
      "   At once: 0.8421052631578948\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 17\n",
      "  Kendall Tau\n",
      "   Combined: 0.15789473684210525\n",
      "   At once: 0.7157894736842105\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 18\n",
      "  Kendall Tau\n",
      "   Combined: 0.39999999999999997\n",
      "   At once: 0.5473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 19\n",
      "  Kendall Tau\n",
      "   Combined: 0.2947368421052632\n",
      "   At once: 0.5473684210526316\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.25\n",
      "   At once: 0.5\n",
      "\n",
      "Test compound 20\n",
      "  Kendall Tau\n",
      "   Combined: 0.2631578947368421\n",
      "   At once: -0.06315789473684211\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.2\n",
      "   At once: 0.2\n",
      "\n",
      "Test compound 21\n",
      "  Kendall Tau\n",
      "   Combined: -0.23157894736842105\n",
      "   At once: -0.23157894736842105\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 0.14285714285714285\n",
      "\n",
      "Test compound 22\n",
      "  Kendall Tau\n",
      "   Combined: 0.19999999999999998\n",
      "   At once: 0.49473684210526314\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 0.5\n",
      "\n",
      "Test compound 23\n",
      "  Kendall Tau\n",
      "   Combined: 0.4210526315789474\n",
      "   At once: 0.08421052631578947\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 0.5\n",
      "\n",
      "Test compound 24\n",
      "  Kendall Tau\n",
      "   Combined: 0.042105263157894736\n",
      "   At once: -0.17894736842105263\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.2\n",
      "   At once: 0.14285714285714285\n",
      "\n",
      "Test compound 25\n",
      "  Kendall Tau\n",
      "   Combined: 0.2631578947368421\n",
      "   At once: 0.43157894736842106\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 0.5\n",
      "\n",
      "Test compound 26\n",
      "  Kendall Tau\n",
      "   Combined: -0.09473684210526316\n",
      "   At once: 0.30526315789473685\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.09090909090909091\n",
      "   At once: 0.25\n",
      "\n",
      "Test compound 27\n",
      "  Kendall Tau\n",
      "   Combined: 0.4842105263157895\n",
      "   At once: 0.45263157894736844\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.3333333333333333\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 28\n",
      "  Kendall Tau\n",
      "   Combined: 0.021052631578947368\n",
      "   At once: -0.042105263157894736\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.1\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 29\n",
      "  Kendall Tau\n",
      "   Combined: 0.10526315789473685\n",
      "   At once: 0.042105263157894736\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.2\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 30\n",
      "  Kendall Tau\n",
      "   Combined: 0.2736842105263158\n",
      "   At once: 0.43157894736842106\n",
      "  Reciprocal Rank\n",
      "   Combined: 0.5\n",
      "   At once: 1.0\n",
      "\n",
      "Test compound 31\n",
      "  Kendall Tau\n",
      "   Combined: 0.25263157894736843\n",
      "   At once: 0.4105263157894737\n",
      "  Reciprocal Rank\n",
      "   Combined: 1.0\n",
      "   At once: 0.3333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate_complete_deoxy import *\n",
    "\n",
    "X, y = load_data(\"desc\", \"yield\", \"both\")\n",
    "X_sf, y_sf = load_data(\"desc\", \"ranking\", \"sulfonyl_fluoride\")\n",
    "X_base, y_base = load_data(\"desc\", \"ranking\", \"base\")\n",
    "X_both, y_both = load_data(\"desc\", \"ranking\", \"both\")\n",
    "print(X_sf.shape, y_sf.shape, X_base.shape, y_base.shape, X_both.shape, y_both.shape)\n",
    "\n",
    "for i in range(32) :\n",
    "    # ranking sulfonyl fluorides first\n",
    "    test_inds = [x for x in range(4*i, 4*i+4)]\n",
    "    train_inds = [x for x in range(X_sf.shape[0]) if x not in test_inds]\n",
    "\n",
    "    X_train_sf, X_test_sf = X_sf[train_inds, :], X_sf[test_inds,:]\n",
    "    y_train_sf, y_test_sf = y_sf[train_inds, :], y_sf[test_inds,:]\n",
    "    std = StandardScaler()\n",
    "    X_train_sf_std = std.fit_transform(X_train_sf)\n",
    "    X_test_sf_std = std.transform(X_test_sf)\n",
    "\n",
    "    rpc_lr = DecisionTreeLabelRanker(\n",
    "                random_state=42, min_samples_split=y_train_sf.shape[1] * 2\n",
    "            )\n",
    "    rpc_lr.fit(X_train_sf_std, y_train_sf)\n",
    "    rpc_pred_rank_sf = rpc_lr.predict(X_test_sf_std)\n",
    "\n",
    "    # Ranking bases\n",
    "    test_inds = [x for x in range(5*i, 5*i+5)]\n",
    "    train_inds = [x for x in range(X_base.shape[0]) if x not in test_inds]\n",
    "\n",
    "    X_train_base, X_test_base = X_base[train_inds, :], X_base[test_inds,:]\n",
    "    y_train_base, y_test_base = y_base[train_inds, :], y_base[test_inds,:]\n",
    "    std = StandardScaler()\n",
    "    X_train_base_std = std.fit_transform(X_train_base)\n",
    "    X_test_base_std = std.transform(X_test_base)\n",
    "    rpc_lr.fit(X_train_base_std, y_train_base)\n",
    "    rpc_pred_rank_base = rpc_lr.predict(X_test_base_std)\n",
    "    # print(rpc_pred_rank_base.shape)\n",
    "\n",
    "    total_pred = np.multiply(rpc_pred_rank_sf, rpc_pred_rank_base.T).flatten()\n",
    "    # print(total_pred)\n",
    "    total_pred_rank = yield_to_ranking(-1 * total_pred)\n",
    "    # print(total_pred_rank)\n",
    "\n",
    "    # predicting both at once\n",
    "    train_inds = [x for x in range(32) if x!=i]\n",
    "\n",
    "    X_train_both, X_test_both = X_both[train_inds, :], X_both[i,:]\n",
    "    y_train_both, y_test_both = y_both[train_inds, :], y_both[i,:]\n",
    "    std = StandardScaler()\n",
    "    X_train_both_std = std.fit_transform(X_train_both)\n",
    "    X_test_both_std = std.transform(X_test_both.reshape(1,-1))\n",
    "    rpc_lr.fit(X_train_both_std, y_train_both)\n",
    "    rpc_pred_rank_both = rpc_lr.predict(X_test_both_std)\n",
    "\n",
    "    # actual yields\n",
    "    y_test = y[20*i:20*(i+1)]\n",
    "    actual_rank = yield_to_ranking(y_test)\n",
    "\n",
    "    # Comparing\n",
    "    print(f\"Test compound {i}\")\n",
    "    print(\"  Kendall Tau\")\n",
    "    print(f\"   Combined: {kendalltau(actual_rank, total_pred_rank).statistic}\")\n",
    "    print(f\"   At once: {kendalltau(actual_rank, rpc_pred_rank_both).statistic}\")\n",
    "    print(\"  Reciprocal Rank\")\n",
    "    total_inds = np.argpartition(total_pred_rank.flatten(), 4)[:4]\n",
    "    total_rr = 1/np.min(actual_rank[total_inds])\n",
    "    once_inds = np.argpartition(rpc_pred_rank_both.flatten(), 4)[:4]\n",
    "    once_rr = 1/np.min(actual_rank[once_inds])\n",
    "    print(f\"   Combined: {total_rr}\")\n",
    "    print(f\"   At once: {once_rr}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.101, 13.68 ,  0.12 ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  7.397],\n",
       "       [ 0.101, 13.68 ,  0.12 ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  6.069],\n",
       "       [ 0.101, 13.68 ,  0.12 ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  4.727],\n",
       "       [ 0.101, 13.68 ,  0.12 ,  1.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  5.305]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
